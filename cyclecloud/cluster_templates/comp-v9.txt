################################
## Cluster Configuration File ##
################################

[cluster comp-v9]
FormLayout = selectionpanel
Category = Schedulers

Autoscale = $Autoscale

    [[node defaults]]
    UsePublicNetwork = $UsePublicNetwork
    Credentials = azure    
    SubnetId = scc-rg9/DefaultNetwork_southcentralus/default 
    Region = $Region
    KeyPairLocation = ~/.ssh/cyclecloud.pem

    # Slurm autoscaling supports both Terminate and Deallocate shutdown policies
    ShutdownPolicy = $configuration_slurm_shutdown_policy

        [[[configuration]]]
        slurm.version = $configuration_slurm_version

        # For fast spin-up after Deallocate, force an immediate re-converge on boot
	cyclecloud.converge_on_boot = true

        [[[cluster-init cyclecloud/slurm:default]]]
        [[[cluster-init comp-v9:default:1.0.0]]]
        Optional = true

    [[node master]]
    MachineType = $MasterMachineType
    ImageName = $MasterImageName
    IsReturnProxy = $ReturnProxy
    AdditionalClusterInitSpecs = $MasterClusterInitSpecs
    CloudInit = '''#!/bin/bash
    echo "cloud-init works" > /tmp/cloud-init.txt
    sudo yum -y install perl-XML-LibXML
    sudo yum -y install cmake
    sudo yum -y install htop
    echo "packages installed" > /tmp/cloud_completed.txt
    '''

        [[[configuration]]]

        [[[cluster-init cyclecloud/slurm:master]]]

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = $UsePublicNetwork
        
	### 
#        [[[volume data]]]
#        Size = 200
#        Persistent = true
#	StorageAccountType = StandardSSD_LRS
#	Mount = data

        # Add 1 premium disk of 3TB size to the NFS export
        [[[volume nfs-1]]]
        Size = 3072
        SSD = true
        Mount = data
        Persistent = true


        [[[configuration cyclecloud.mounts.data]]]
        mountpoint = /data
        fs_type = ext4

	[[[configuration cyclecloud.exports.nfs_data]]]
	type = nfs
	export_path = /data
        ### End changes

        [[[input-endpoint ganglia]]]
        PrivatePort = 8652
        PublicPort = 8652


    [[nodearray hpc]]
    MachineType = $HPCMachineType
    ImageName = $HPCImageName
    MaxCoreCount = $MaxHPCExecuteCoreCount
    Azure.MaxScalesetSize = $HPCMaxScalesetSize
    AdditionalClusterInitSpecs = $HPCClusterInitSpecs
    CloudInit = '''#!/bin/bash
    echo "cloud-init works" > /tmp/cloud-init.txt
    sudo yum -y install epel-release
    sudo yum -y install perl-XML-LibXML
    sudo yum -y install cmake
    sudo yum -y install htop
    echo "packages installed" > /tmp/cloud_completed.txt
    '''

        [[[configuration]]]
        slurm.autoscale = true
        slurm.default_partition = false
        slurm.hpc = true

        [[[cluster-init cyclecloud/slurm:execute]]]

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = $ExecuteNodesPublic

	### begin changes
	[[[configuration cyclecloud.mounts.nfs_data]]]
	type = nfs
	mountpoint = /data
	export_path = /data
	### end changes
	


    [[nodearray development]]
    MachineType = $developmentMachineType
    ImageName = $HTCImageName
    MaxCoreCount = $MaxHTCExecuteCoreCount
    Interruptible = $HTCUseLowPrio
    AdditionalClusterInitSpecs = $HTCClusterInitSpecs
    CloudInit = '''#!/bin/bash
    sudo yum -y install epel-release
    sudo yum -y install cmake
    sudo yum -y install htop
    echo "packages installed" > /tmp/cloud_completed.txt
    '''

        [[[configuration]]]
        slurm.autoscale = true
        slurm.default_partition = true
        slurm.hpc = true

        [[[cluster-init cyclecloud/slurm:execute]]]

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = $ExecuteNodesPublic

	### begin changes
	[[[configuration cyclecloud.mounts.nfs_data]]]
	type = nfs
	mountpoint = /data
	export_path = /data
	### end changes

    [[nodearray gpu]]
    Extends = hpc
    Machinetype = $GPUMachineType
    ImageName = $gpuImageName
    MaxCoreCount = $MaxgpuExecuteCoreCount
    CloudInit = '''#!/bin/bash
    echo "cloud-init works" > /tmp/cloud-init.txt
    sudo yum -y install epel-release
    sudo yum -y install htop
    sudo /data/cloud-init/nvidia.sh
    '''
        [[[configuration]]]
        slurm.autoscale = true
        slurm.hpc = true
        slurm.default_partition = false
        ### begin changes
        [[[configuration cyclecloud.mounts.nfs_data]]]
        type = nfs
        mountpoint = /data
        export_path = /data
        ### end changes

#test node array to see if we are limited by number of slurm partitions
    [[nodearray hpc2]]
    MachineType = $hpc2MachineType
    ImageName = $HTCImageName
    MaxCoreCount = $MaxHPC2ExecuteCoreCount
    Interruptible = $HTCUseLowPrio
    AdditionalClusterInitSpecs = $HTCClusterInitSpecs
    CloudInit = '''#!/bin/bash
    echo "cloud-init works" > /tmp/cloud-init.txt
    sudo yum -y install epel-release
    sudo yum -y install perl-XML-LibXML
    sudo yum -y install cmake
    sudo yum -y install htop
    echo "packages installed" > /tmp/cloud_completed.txt
    '''

        [[[configuration]]]
        slurm.autoscale = true
        slurm.default_partition = false
        slurm.hpc = true

        [[[cluster-init cyclecloud/slurm:execute]]]

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = $ExecuteNodesPublic

        ### begin changes
        [[[configuration cyclecloud.mounts.nfs_data]]]
        type = nfs
        mountpoint = /data
        export_path = /data
        ### end changes



[parameters About]
Order = 1

    [[parameters About Slurm]]

        [[[parameter slurm]]]
        HideLabel = true
        Config.Plugin = pico.widget.HtmlTemplateWidget
        Config.Template := "<table><tr><td><img src='static/cloud/cluster/ui/ClusterIcon/slurm.png' width='192' height='192'></td></tr><tr><td><p>Slurm is a highly configurable open source workload manager. See the <a href=\"https://www.schedmd.com/\" target=\"_blank\">Slurm project site</a> for an overview.</p><p>Follow the instructions in the <a href=\"https://github.com/azure/cyclecloud-slurm/\" target=\"_blank\">README</a> for details on instructions on extending and configuring the Project for your environment.</p></td></tr></table>"

[parameters Required Settings]
Order = 10

    [[parameters Virtual Machines ]]
    Description = "The cluster, in this case, has two roles: the scheduler master-node with shared filer and the execute hosts. Configure which VM types to use based on the requirements of your application."
    Order = 20

        [[[parameter Region]]]
        Label = Region
        Description = Deployment Location
        ParameterType = Cloud.Region
        DefaultValue = southcentralus 

        [[[parameter MasterMachineType]]]
        Label = Master VM Type
        Description = The VM type for scheduler master and shared filer.
        ParameterType = Cloud.MachineType
        DefaultValue = Standard_D16_v3

        [[[parameter HPCMachineType]]]
        Label = HPC VM Type
        Description = The VM type for HPC execute nodes
        ParameterType = Cloud.MachineType
        DefaultValue = Standard_HC44rs

        [[[parameter developmentMachineType]]]
        Label = HTC VM Type
        Description = The VM type for HTC execute nodes
        ParameterType = Cloud.MachineType
        DefaultValue = Standard_D16_v3

        [[[parameter GPUMachineType]]]
        Label = GPU VM Type
        Description = The VM type for GPU execute nodes
        ParameterType = Cloud.MachineType
        DefaultValue = Standard_NC12s_v2

#hpc2 nodearray to verify some things
        [[[parameter hpc2MachineType]]]
        Label = hpc2 VM Type
        Description = The VM type for hpc2 execute nodes
        ParameterType = Cloud.MachineType
        DefaultValue = Standard_D32s_v3

    [[parameters Auto-Scaling]]
    Description = "The cluster can autoscale to the workload, adding execute hosts as jobs are queued. To enable this check the box below and choose the initial and maximum core counts for the cluster"
    Order = 30

        [[[parameter Autoscale]]]
        Label = Autoscale
        DefaultValue = true
        Widget.Plugin = pico.form.BooleanCheckBox
        Widget.Label = Start and stop execute instances automatically

        [[[parameter MaxHPCExecuteCoreCount]]]
        Label = Max HPC Cores
        Description = The total number of HPC execute cores to start
        DefaultValue = 1760
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.IntegerOnly = true

        [[[parameter MaxHPC2ExecuteCoreCount]]]
        Label = Max HPC2 Cores
        Description = The total number of HPC2 execute cores to start
        DefaultValue = 1024
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.IntegerOnly = true

        [[[parameter MaxHTCExecuteCoreCount]]]
        Label = Max HTC Cores
        Description = The total number of HTC execute cores to start
        DefaultValue = 320
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.IntegerOnly = true

        [[[parameter MaxgpuExecuteCoreCount]]]
        Label = Max gpu Cores
        Description = The total number of gpu execute cores to start
        DefaultValue = 600
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.IntegerOnly = true


        [[[parameter HPCMaxScalesetSize]]]
        Label = Max VMs per Scaleset
        Description = The maximum number of VMs created per VM Scaleset e.g. switch in Slurm.
        DefaultValue = 100
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.IntegerOnly = true


        [[[parameter HTCUseLowPrio]]]
        Label = Low Priority
        DefaultValue = false
        Widget.Plugin = pico.form.BooleanCheckBox
        Widget.Label = Use low priority instances for HTC execute hosts

    [[parameters Networking]]
    Order = 40

        [[[parameter SubnetId]]]
        Label = Subnet ID
        Description = Subnet Resource Path (ResourceGroup/VirtualNetwork/Subnet)
        ParameterType = Azure.Subnet
        Required = True


[parameters Advanced Settings]
Order = 20

    [[parameters Azure Settings]]
    Order = 10 

        [[[parameter Credentials]]]
        Description = The credentials for the cloud provider
        ParameterType = Cloud.Credentials

    [[parameters Slurm Settings ]]
    Description = "Section for configuring Slurm"
    Order = 5

        [[[parameter configuration_slurm_version]]]
        Required = True
        Label = Slurm Version
        Description = Version of Slurm to install on the cluster
        ParameterType = StringList
        Config.Plugin = pico.form.Dropdown
        Config.FreeForm = true
        Config.Entries := {[Value="19.05.5-1"], [Value="18.08.9-1"]}
        DefaultValue = 19.05.5-1

        [[[parameter configuration_slurm_shutdown_policy]]]
	Label = ShutdownPolicy
        description = By default, autostop will Delete stopped VMS for lowest cost.  Optionally, Stop/Deallocate the VMs for faster restart instead.
        DefaultValue = Terminate
        config.plugin = pico.control.AutoCompleteDropdown
            [[[[list Config.Entries]]]]
            Name = Terminate
            Label = Terminate
            [[[[list Config.Entries]]]]
            Name = Deallocate
            Label = Deallocate
	

    [[parameters Software]]
    Description = "Specify the scheduling software, and base OS installed on all nodes, and optionally the cluster-init and chef versions from your Locker."
    Order = 10

        [[[parameter MasterImageName]]]
        Label = Master OS
        ParameterType = Cloud.Image
        Config.OS = linux
        DefaultValue = cycle.image.centos7
        Config.Filter := Package in {"cycle.image.centos7", "cycle.image.ubuntu18"}

        [[[parameter HPCImageName]]]
        Label = HPC OS
        ParameterType = Cloud.Image
        Config.OS = linux
        DefaultValue = cycle.image.centos7
        Config.Filter := Package in {"cycle.image.centos7", "cycle.image.ubuntu18"}

        [[[parameter HTCImageName]]]
        Label = HTC OS
        ParameterType = Cloud.Image
        Config.OS = linux
        DefaultValue = cycle.image.centos7
        Config.Filter := Package in {"cycle.image.centos7", "cycle.image.ubuntu18"}

        [[[parameter gpuImageName]]]
        Label = gpu OS
        ParameterType = Cloud.Image
        Config.OS = linux
        DefaultValue = cycle.image.centos7
        Config.Filter := Package in {"cycle.image.centos7", "cycle.image.ubuntu18"}

        [[[parameter MasterClusterInitSpecs]]]
        Label = Master Cluster-Init
        DefaultValue = =undefined
        Description = Cluster init specs to apply to the master node
        ParameterType = Cloud.ClusterInitSpecs
    
        [[[parameter HTCClusterInitSpecs]]]
        Label = HTC Cluster-Init
        DefaultValue = =undefined
        Description = Cluster init specs to apply to HTC execute nodes
        ParameterType = Cloud.ClusterInitSpecs
        
        [[[parameter HPCClusterInitSpecs]]]
        Label = HPC Cluster-Init
        DefaultValue = =undefined
        Description = Cluster init specs to apply to HPC execute nodes
        ParameterType = Cloud.ClusterInitSpecs
	

    [[parameters Advanced Networking]]
    Description = Advanced networking settings

        [[[parameter ReturnProxy]]]
        Label = Return Proxy
        DefaultValue = true
        ParameterType = Boolean
        Config.Label = Use SSH tunnel to connect to CycleCloud (required if direct access is blocked)

        [[[parameter UsePublicNetwork]]]
        Label = Public Head Node
        DefaultValue = true
        ParameterType = Boolean
        Config.Label = Access master node from the Internet

        [[[parameter ExecuteNodesPublic]]]
        Label = Public Execute
        DefaultValue = false
        ParameterType = Boolean
        Config.Label = Access execute nodes from the Internet
        Conditions.Excluded := UsePublicNetwork isnt true
